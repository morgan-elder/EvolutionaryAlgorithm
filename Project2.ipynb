{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project 2\n",
        "\n",
        "Morgan Elder<br>\n",
        "Ben Vuong<br>\n",
        "CS 4320"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Write a brief (no more than a paragraph) note on the importance of the choice of \n",
        "parameter settings in evolutionary algorithms. Or argue, with well-articulated, precise \n",
        "reasons (one paragraph only), that parameters do not really matter in EC.  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I would say that when working with evolutionary algorithms, diversity is very important for the growth and success of the evolutionary algorithms. There should not be one indiviudual within the population that over takes the other. If that would happen then there would be stagnation within the growth of the algorithms. In order to prevent such an event of happening and encourage growth and diversity, it is important to focus on the choice of parameters settings in evolutionary algorithms. If good parameters were choosen, there will be higher chances or growth and diversity to happen and the inverse would result in a higher chance of stangnation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evolutionary algorithm (EA) parameters directly influence the exploration with diverse populations and exploitation of fit individuals. Parameters include all of the algorithm design choices such as genetic operators, operator parameters, stopping conditions, population size and seed. For example, parameters like the mutation rate or cross over probability can increase exploration whereas selection/sampling method can increase exploitation. Because EAs are stochastic, the applicability of an EA, more specfically the EA parameters, accross different problems, problem instances, and sizes must be compared using statistical methods and many runs that are *iid*. Therefore, parameter settings are an important part of the optimization process that must strike a balance between generalizability, computational cost, and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVLWKr_PcMKA"
      },
      "source": [
        "# De Jong Function 5: Variation of Shekel's Function \n",
        "\n",
        "The objective of this project is to minimize Shekel's function using parameters from De Jong function #5:\n",
        "\n",
        "$$f(\\vec{x}) = \\left(0.002 + \\sum_{i=1}^{25}\\frac{1}{i + (x_1 - a_{1i})^6 + (x_2 - a_{2i})^6}\\right)^{-1}$$\n",
        "\n",
        "where $$\n",
        "\\textbf{a} =\n",
        " \\begin{pmatrix}\n",
        "    -32 & -16 & 0 & 16 & 32 & -32 & \\ldots & 0 & 16 & 32 \\\\\n",
        "    -32 & -32 & -32 & -32 & -32 & -16 & \\ldots & 32 & 32 & 32\n",
        " \\end{pmatrix}$$\n",
        "\n",
        "The number of dimensions is 2 and the input domain is $-65.536 \\le x_i \\le 65.536$ for $i=1,2$. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QPHBl0oiNVu"
      },
      "outputs": [],
      "source": [
        "#import modules\n",
        "import numpy as np\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCRBtaBwXA1L"
      },
      "source": [
        "## Optimization Goals\n",
        "\n",
        "Use the Optimization_Goal class as an enum type in order to define a goal variable as either min or max."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjWPX6o8SlBH"
      },
      "outputs": [],
      "source": [
        " class Optimization_Goal(Enum):\n",
        "  MINIMIZE = 1\n",
        "  MAXIMIZE = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdMpsrQmZkmI"
      },
      "source": [
        "## Genetic Algorithm Problems\n",
        "\n",
        "Genetic algorithms are suited for optimization problems. The Problem class contains the definitions of optimization problems as subclasses. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdkCDF074zOu"
      },
      "outputs": [],
      "source": [
        "class Problem():\n",
        "  \"\"\"The Problem class defines the problems contains the definitions of\n",
        "  of problems. Problems include any information such as the optimization\n",
        "  goal (min/max), objective function, input dimension, domain/range constraints, \n",
        "  and more.\"\"\"\n",
        "  class De_Jong_Function_5():\n",
        "    \"\"\"De Jong function #5 is variation of Shekel's foxeholes problem involving\n",
        "    25 local minima, 2 dimensions, and predefined constants.\n",
        "    This problem is suited for multimodal optimization.\"\"\"\n",
        "    dimensions=2\n",
        "    goal=Optimization_Goal.MINIMIZE\n",
        "    upper_bounds = [65.536, 65.536]\n",
        "    lower_bounds = [-65.536, 65.536]\n",
        "    constants_array = np.array(\n",
        "        [[-32., -16., 0., 16., 32., -32., -16., 0., 16., 32., -32., -16., 0., \n",
        "          16., 32., -32., -16., 0., 16., 32., -32., -16., 0., 16., 32.],\n",
        "         [-32., -32., -32., -32., -32., -16., -16., -16., -16., -16., 0., 0., \n",
        "          0., 0., 0., 16., 16., 16., 16., 16., 32., 32., 32., 32., 32.]]\n",
        "      )\n",
        "    def objective_function(self, X):\n",
        "      # array representing the 1st to 25th elements of the summation\n",
        "      array_i = np.arange(1, self.constants_array.shape[1]+1, step=1)\n",
        "      results = (0.002 + np.sum(1/(array_i \n",
        "                          + (X[:,[0]] - self.constants_array[0])**6\n",
        "                          + (X[:, [1]] - self.constants_array[1])**6), axis=1))**-1\n",
        "      return results    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHeW-mHb0K1F"
      },
      "outputs": [],
      "source": [
        "problem = Problem.De_Jong_Function_5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqWr-KVQKdjm",
        "outputId": "ab555621-5ad0-47eb-f559-4b40a62a31f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([67.47209734, 67.47209734])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[1,2], [1,2]])\n",
        "problem.objective_function(x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
